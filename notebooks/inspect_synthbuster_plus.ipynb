{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Dataset Inspection: SynthBuster+\n",
    "\n",
    "This notebook inspects the SynthBuster+ dataset loaded from `data/datasets/synthbuster-plus`.\n",
    "\n",
    "We'll explore:\n",
    "1. Dataset structure and statistics\n",
    "2. Sample images from each class\n",
    "3. Label distribution\n",
    "4. Image properties and metadata\n",
    "5. Paired sample visualization using `plot_collage()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datasets import load_from_disk\n",
    "from PIL import Image\n",
    "\n",
    "# Import plot_collage from clip_cues\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from src.clip_cues import plot_collage\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load the SynthBuster+ dataset from the local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from disk\n",
    "dataset_path = Path(\"../data/datasets/synthbuster-plus\")\n",
    "\n",
    "if dataset_path.exists():\n",
    "    dataset = load_from_disk(str(dataset_path))\n",
    "    print(\"✓ Dataset loaded successfully!\")\n",
    "    print(f\"  Location: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"⚠ Dataset not found at {dataset_path}\")\n",
    "    print(\"Please run: python scripts/download_dataset.py synthbuster-plus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "Examine the dataset structure, splits, and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset structure\n",
    "print(\"Dataset Splits:\")\n",
    "print(f\"{'='*60}\")\n",
    "for split_name in dataset.keys():\n",
    "    split_data = dataset[split_name]\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    print(f\"  Number of examples: {len(split_data):,}\")\n",
    "    print(f\"  Features: {list(split_data.features.keys())}\")\n",
    "    print(f\"  Feature types:\")\n",
    "    for feature_name, feature_type in split_data.features.items():\n",
    "        print(f\"    - {feature_name}: {feature_type}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Label Distribution\n",
    "\n",
    "Analyze the distribution of real vs synthetic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze label distribution for each split\n",
    "for split_name in dataset.keys():\n",
    "    split_data = dataset[split_name]\n",
    "\n",
    "    # Count labels\n",
    "    labels = split_data['label']\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    print(f\"\\n{split_name} - Label Distribution:\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    print(f\"  Real (0):      {label_counts[0]:,} ({label_counts[0]/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  Synthetic (1): {label_counts[1]:,} ({label_counts[1]/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  Total:         {len(labels):,}\")\n",
    "\n",
    "    # Visualize with seaborn\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "    # Prepare data for seaborn\n",
    "    labels_list = ['Real', 'Synthetic']\n",
    "    counts = [label_counts[0], label_counts[1]]\n",
    "    colors = ['green', 'red']\n",
    "\n",
    "    # Create barplot with seaborn\n",
    "    sns.barplot(\n",
    "        x=labels_list,\n",
    "        y=counts, hue=labels_list, legend=False, palette=colors, alpha=0.7, edgecolor='black', ax=ax)\n",
    "\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(f'{split_name} - Label Distribution', fontsize=14)\n",
    "\n",
    "    # Add count labels on bars\n",
    "    for i, (label, count) in enumerate(zip(labels_list, counts)):\n",
    "        ax.text(i, count, f'{count:,} ({count/len(labels)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Inspect Sample Examples\n",
    "\n",
    "Look at the first few examples to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first example from train split\n",
    "if 'train' in dataset:\n",
    "    example = dataset['train'][0]\n",
    "\n",
    "    print(\"Example structure:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for key, value in example.items():\n",
    "        if key == 'image':\n",
    "            print(f\"  {key}: PIL Image ({value.size}, mode={value.mode})\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first example from train split\n",
    "if 'train' in dataset:\n",
    "    example = dataset['train'][-1]\n",
    "\n",
    "    print(\"Example structure:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for key, value in example.items():\n",
    "        if key == 'image':\n",
    "            print(f\"  {key}: PIL Image ({value.size}, mode={value.mode})\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first example from train split\n",
    "if 'train' in dataset:\n",
    "    example = dataset['train'][-1]\n",
    "\n",
    "    print(\"Example structure:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for key, value in example.items():\n",
    "        if key == 'image':\n",
    "            print(f\"  {key}: PIL Image ({value.size}, mode={value.mode})\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Visualize Sample Images\n",
    "\n",
    "Display sample images from each class (real and synthetic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset_split, n_samples=5, seed=42):\n",
    "    \"\"\"\n",
    "    Visualize sample images from each class.\n",
    "\n",
    "    Args:\n",
    "        dataset_split: Dataset split to visualize\n",
    "        n_samples: Number of samples per class\n",
    "        seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get indices for each class\n",
    "    real_indices = [i for i, label in enumerate(dataset_split['label']) if label == 0]\n",
    "    synthetic_indices = [i for i, label in enumerate(dataset_split['label']) if label == 1]\n",
    "\n",
    "    # Sample random indices\n",
    "    real_sample_idx = np.random.choice(real_indices, min(n_samples, len(real_indices)), replace=False)\n",
    "    synthetic_sample_idx = np.random.choice(synthetic_indices, min(n_samples, len(synthetic_indices)), replace=False)\n",
    "\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(3*n_samples, 6))\n",
    "\n",
    "    # Plot real images\n",
    "    for i, idx in enumerate(real_sample_idx):\n",
    "        example = dataset_split[int(idx)]\n",
    "        axes[0, i].imshow(example['image'])\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Add title with metadata\n",
    "        title = f\"Real\\n\"\n",
    "        if 'source' in example:\n",
    "            title += f\"Source: {example['source']}\"\n",
    "        axes[0, i].set_title(title, fontsize=10, color='green', fontweight='bold')\n",
    "\n",
    "    # Plot synthetic images\n",
    "    for i, idx in enumerate(synthetic_sample_idx):\n",
    "        example = dataset_split[int(idx)]\n",
    "        axes[1, i].imshow(example['image'])\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "        # Add title with metadata\n",
    "        title = f\"Synthetic\\n\"\n",
    "        if 'source' in example:\n",
    "            title += f\"Source: {example['source']}\"\n",
    "        axes[1, i].set_title(title, fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from train split\n",
    "if 'train' in dataset:\n",
    "    print(\"Sample images from training set:\")\n",
    "    visualize_samples(dataset['train'], n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Visualize More Samples\n",
    "\n",
    "Display additional samples with different random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with different seed\n",
    "if 'train' in dataset:\n",
    "    print(\"Different random samples:\")\n",
    "    visualize_samples(dataset['train'], n_samples=5, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Visualize Paired Samples with plot_collage()\n",
    "\n",
    "Use the `plot_collage()` function to create a grid visualization of paired samples (real image + synthetic versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_paired_samples_collage(dataset, split_name='train', n_pairs=6, seed=42):\n",
    "    \"\"\"\n",
    "    Visualize paired samples using plot_collage: real image + synthetic versions.\n",
    "\n",
    "    Args:\n",
    "        dataset: Dataset dict\n",
    "        split_name: Dataset split to use\n",
    "        n_pairs: Number of image pairs (rows) to display\n",
    "        seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    split_data = dataset[split_name]\n",
    "\n",
    "    # Get real image indices\n",
    "    idx_real = np.where(np.array(split_data[\"label\"]) == 0)[0]\n",
    "    image_ids = np.array(split_data[\"image_id\"])\n",
    "\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Sample random real images - np.random.choice returns actual values, not indices\n",
    "    sampled_real_indices = np.random.choice(idx_real, n_pairs, replace=False)\n",
    "    sampled_image_ids = set(split_data.select(sampled_real_indices.tolist())[\"image_id\"])\n",
    "\n",
    "    # Get all indices with these image_ids (real + synthetic versions)\n",
    "    idx_to_select = np.where(np.isin(image_ids, list(sampled_image_ids)))[0]\n",
    "    ds_subset = split_data.select(idx_to_select.tolist())\n",
    "\n",
    "    print(f\"Selected {len(sampled_real_indices)} real images\")\n",
    "    print(f\"Subset size: {len(ds_subset)} (includes synthetic versions)\")\n",
    "\n",
    "    # Group images by image_id\n",
    "    image_groups = defaultdict(list)\n",
    "\n",
    "    for idx, example in enumerate(ds_subset):\n",
    "        image_id = example['image_id']\n",
    "        image_groups[image_id].append(idx)\n",
    "\n",
    "    # Find groups that have both real and synthetic versions\n",
    "    paired_groups = []\n",
    "    for base_id, indices in image_groups.items():\n",
    "        examples = [ds_subset[i] for i in indices]\n",
    "        # Check if we have both real and synthetic\n",
    "        labels = [ex['label'] for ex in examples]\n",
    "        if 0 in labels and 1 in labels:\n",
    "            paired_groups.append((base_id, indices))\n",
    "\n",
    "    print(f\"Found {len(paired_groups)} image groups with both real and synthetic versions\")\n",
    "\n",
    "    if len(paired_groups) == 0:\n",
    "        print(\"No paired samples found in this dataset.\")\n",
    "        return\n",
    "\n",
    "    # Prepare data for plot_collage\n",
    "    # Each row: real image (first) + synthetic versions\n",
    "    max_versions = max(len(indices) for _, indices in paired_groups)\n",
    "    n_rows = len(paired_groups)\n",
    "    n_cols = max_versions\n",
    "\n",
    "    images = []\n",
    "    row_labels = []\n",
    "    col_labels_collected = []  # Collect column labels from first row\n",
    "\n",
    "    for row_idx, (base_id, indices) in enumerate(paired_groups):\n",
    "        examples = [ds_subset[i] for i in indices]\n",
    "        # Sort: real first, then synthetic\n",
    "        sorted_examples = sorted(examples, key=lambda x: x['label'])\n",
    "\n",
    "        row_images = []\n",
    "        row_sources = []\n",
    "\n",
    "        for example in sorted_examples:\n",
    "            row_images.append(example['image'])\n",
    "            row_sources.append(example['source'])\n",
    "\n",
    "        # Collect column labels from first row\n",
    "        if row_idx == 0:\n",
    "            col_labels_collected = row_sources.copy()\n",
    "\n",
    "        # Pad row if needed\n",
    "        while len(row_images) < n_cols:\n",
    "            # Add blank image for padding\n",
    "            blank_img = Image.new('RGB', (224, 224), color='white')\n",
    "            row_images.append(blank_img)\n",
    "\n",
    "        images.extend(row_images)\n",
    "        row_labels.append(base_id)\n",
    "\n",
    "    # Pad column labels if needed\n",
    "    while len(col_labels_collected) < n_cols:\n",
    "        col_labels_collected.append(\"\")\n",
    "\n",
    "    # Plot using plot_collage without individual captions\n",
    "    fig, ax = plot_collage(\n",
    "        images=images,\n",
    "        captions=None,  # No individual captions\n",
    "        row_labels=row_labels,\n",
    "        col_labels=col_labels_collected,\n",
    "        nrows=n_rows,\n",
    "        ncols=n_cols,\n",
    "        title=\"SynthBuster+: Paired Real (Raise1K) and Synthetic Images\"\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Visualize paired samples\n",
    "fig, ax = visualize_paired_samples_collage(dataset, split_name='train', n_pairs=6, seed=123)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../examples/synthbuster-plus_paired_samples_collage.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Analyze Image Properties\n",
    "\n",
    "Examine image dimensions, formats, and other properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(dataset_split, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Analyze properties of images in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_split: Dataset split to analyze\n",
    "        n_samples: Number of samples to analyze\n",
    "    \"\"\"\n",
    "    # Sample indices\n",
    "    n_samples = min(n_samples, len(dataset_split))\n",
    "    indices = np.random.choice(len(dataset_split), n_samples, replace=False)\n",
    "\n",
    "    widths = []\n",
    "    heights = []\n",
    "    labels = []\n",
    "    modes = []\n",
    "\n",
    "    print(f\"Analyzing {n_samples} images...\")\n",
    "\n",
    "    for idx in indices:\n",
    "        example = dataset_split[int(idx)]\n",
    "        img = example['image']\n",
    "        widths.append(img.size[0])\n",
    "        heights.append(img.size[1])\n",
    "        labels.append(example['label'])\n",
    "        modes.append(img.mode)\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"\\nImage Statistics (based on {n_samples} samples):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nWidth:\")\n",
    "    print(f\"  Min: {min(widths)}px\")\n",
    "    print(f\"  Max: {max(widths)}px\")\n",
    "    print(f\"  Mean: {np.mean(widths):.1f}px\")\n",
    "    print(f\"  Median: {np.median(widths):.1f}px\")\n",
    "\n",
    "    print(f\"\\nHeight:\")\n",
    "    print(f\"  Min: {min(heights)}px\")\n",
    "    print(f\"  Max: {max(heights)}px\")\n",
    "    print(f\"  Mean: {np.mean(heights):.1f}px\")\n",
    "    print(f\"  Median: {np.median(heights):.1f}px\")\n",
    "\n",
    "    print(f\"\\nImage Modes:\")\n",
    "    mode_counts = Counter(modes)\n",
    "    for mode, count in mode_counts.most_common():\n",
    "        print(f\"  {mode}: {count} ({count/len(modes)*100:.1f}%)\")\n",
    "\n",
    "    # Create scatterplot (height vs width)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Prepare data for seaborn\n",
    "    label_names = ['Real' if l == 0 else 'Synthetic' for l in labels]\n",
    "\n",
    "    # Create scatterplot with seaborn\n",
    "    sns.scatterplot(x=widths, y=heights, hue=label_names,\n",
    "                    palette={'Real': 'green', 'Synthetic': 'red'},\n",
    "                    alpha=0.6, s=50, edgecolor='black', linewidth=0.5, ax=ax)\n",
    "\n",
    "    # Add mean lines\n",
    "    ax.axvline(np.mean(widths), color='blue', linestyle='--', linewidth=2,\n",
    "               label=f'Mean Width: {np.mean(widths):.1f}px', alpha=0.7)\n",
    "    ax.axhline(np.mean(heights), color='orange', linestyle='--', linewidth=2,\n",
    "               label=f'Mean Height: {np.mean(heights):.1f}px', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Width (pixels)', fontsize=12)\n",
    "    ax.set_ylabel('Height (pixels)', fontsize=12)\n",
    "    ax.set_title('Image Dimensions: Height vs Width', fontsize=14, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze train split\n",
    "if 'train' in dataset:\n",
    "    analyze_image_properties(dataset['train'], n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Analyze Source Distribution\n",
    "\n",
    "If the dataset has a 'source' field, analyze the distribution of different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'source' field exists\n",
    "if 'train' in dataset and 'source' in dataset['train'].features:\n",
    "    for split_name in dataset.keys():\n",
    "        split_data = dataset[split_name]\n",
    "\n",
    "        # Count sources\n",
    "        sources = split_data['source']\n",
    "        source_counts = Counter(sources)\n",
    "\n",
    "        print(f\"\\n{split_name} - Source Distribution:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for source, count in source_counts.most_common():\n",
    "            print(f\"  {source:30}: {count:6,} ({count/len(sources)*100:5.1f}%)\")\n",
    "\n",
    "        # Visualize if there aren't too many sources\n",
    "        if len(source_counts) <= 20:\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            sources_list = [s for s, _ in source_counts.most_common()]\n",
    "            counts = [c for _, c in source_counts.most_common()]\n",
    "\n",
    "            bars = ax.barh(sources_list, counts, alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('Count', fontsize=12)\n",
    "            ax.set_title(f'{split_name} - Source Distribution', fontsize=14, fontweight='bold')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No 'source' field found in dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Print a final summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: SynthBuster+\")\n",
    "print(f\"Location: {dataset_path}\")\n",
    "print(f\"\\nSplits:\")\n",
    "for split_name in dataset.keys():\n",
    "    split_data = dataset[split_name]\n",
    "    labels = split_data['label']\n",
    "    label_counts = Counter(labels)\n",
    "    print(f\"  {split_name:10}: {len(split_data):6,} samples (Real: {label_counts[0]:6,}, Synthetic: {label_counts[1]:6,})\")\n",
    "\n",
    "print(f\"\\nFeatures: {list(dataset['train'].features.keys())}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
